{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28001,"status":"ok","timestamp":1716703780178,"user":{"displayName":"lim","userId":"04420829670387596982"},"user_tz":-480},"id":"yVUy-RPNXLf4","outputId":"ee6f1b0f-4d7b-4e0b-ee40-e2a049001fda"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7TQHZZB1e3e","executionInfo":{"status":"ok","timestamp":1716703790437,"user_tz":-480,"elapsed":10263,"user":{"displayName":"lim","userId":"04420829670387596982"}},"outputId":"59429844-2060-4c66-d5ec-ddc29d07a64b"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet50_coco-cd0a2569.pth\n","100%|██████████| 161M/161M [00:00<00:00, 174MB/s]\n"]}],"source":["import cv2\n","import torch\n","import numpy as np\n","from PIL import Image\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","\n","# Load the pre-trained model from PyTorch Hub\n","model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\n","model.eval()\n","\n","if torch.cuda.is_available():\n","    model.to('cuda')\n","\n","# Define the transformation\n","preprocess = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RwAd86om1hgs","executionInfo":{"status":"ok","timestamp":1716706683688,"user_tz":-480,"elapsed":2880479,"user":{"displayName":"lim","userId":"04420829670387596982"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b99df4c7-0eba-418b-9ef7-99f38389fcd5"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n"]}],"source":["import zipfile\n","from google.colab import files\n","import os\n","\n","# Initialize video capture\n","video_path = '/content/drive/Shareddrives/TUG dataset/TUG dataset/17/PD/side/PD_side_8.MOV'\n","cap = cv2.VideoCapture(video_path)\n","if not cap.isOpened():\n","    print(\"Error opening video file\")\n","    exit()\n","\n","output_dir = 'silhouette_frames'\n","os.makedirs(output_dir, exist_ok=True)\n","frame_idx = 0\n","\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    input_image = Image.fromarray(frame_rgb)\n","    input_tensor = preprocess(input_image)\n","    input_batch = input_tensor.unsqueeze(0)\n","    if torch.cuda.is_available():\n","        input_batch = input_batch.to('cuda')\n","    with torch.no_grad():\n","        output = model(input_batch)['out'][0]\n","    output_predictions = output.argmax(0)\n","    binary_mask = (output_predictions == 15).byte().cpu().numpy()\n","    silhouette_image = Image.fromarray((binary_mask * 255).astype(np.uint8))\n","    silhouette_image.save(os.path.join(output_dir, f'silhouette_frame_{frame_idx}.png'))\n","    frame_idx += 1\n","\n","cap.release()"]},{"cell_type":"code","source":["from google.colab import files as colab_files\n","# Zip files\n","zip_filename = 'silhouettes.zip'\n","zipf = zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED)\n","for root, dirs, files in os.walk(output_dir):\n","    for file in files:\n","        zipf.write(os.path.join(root, file), arcname=file)\n","zipf.close()\n","\n","# Download ZIP file\n","colab_files.download(zip_filename)"],"metadata":{"id":"PkA_EvnOes7K","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1716706684905,"user_tz":-480,"elapsed":1220,"user":{"displayName":"lim","userId":"04420829670387596982"}},"outputId":"529cec2f-b78d-4f30-bc56-1154c2ee90d6"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_0205d359-b3fb-4d87-abe2-b2bbd2a03f99\", \"silhouettes.zip\", 11676755)"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"kaVQkwI-hVsk"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}